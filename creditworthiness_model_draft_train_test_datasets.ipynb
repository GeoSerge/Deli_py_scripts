{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Модель по платежеспособности 11/23/2020\n",
    "1. Модель на основе регистрационных данных\n",
    "    * Низкое качество предсказания (варьируется в зависимости от типа штрафа)\n",
    "    * Варианты улучшения качества предсказания:\n",
    "        * Генерация новых фичей\n",
    "        * Различные статистические техники (метод K-folds итд)\n",
    "        * Добавить разбивку штрафов по договору на более мелкие категории\n",
    "        * Исправить ошибки на которые ругается Python\n",
    "        * Использовать другие типы зависимостей (не только линейные) для параметров, например логистическую для возраста/стажа\n",
    "2. Модель на основе данных об использовании сервиса\n",
    "    * Качество предсказание неплохое (так же варьируется в зависимости от типа штрафа)\n",
    "    * Дальнейшие действия:\n",
    "        * То же самое что и для модели на основе регистрационных данных + добавление параметра % оплаты и разбивка датасета\n",
    "          на временные интервалы для тестирования качества модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PREPARING DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3063: DtypeWarning: Columns (11) have mixed types.Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# OPENING RAW DATAFRAME\n",
    "df_train = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/raw_data_1_2019_2_2020.csv')\n",
    "df_test = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/raw_data_3_2020_8_2020.csv')\n",
    "\n",
    "# REMOVING DUPLICATES\n",
    "df_train = df_train.drop_duplicates('user_id')\n",
    "df_test = df_test.drop_duplicates('user_id')\n",
    "\n",
    "# OPENING CONTRACT PENALTIES BY TYPE AND MERGING IT WITH THE MAIN DATAFRAME\n",
    "ct_train = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/raw_data_contract_penalties_1_2019_2_2020.csv')\n",
    "ct_test = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/raw_data_contract_penalties_3_2020_8_2020.csv')\n",
    "df_train = pd.merge(df_train,ct_train, on = 'user_id', how = 'left')\n",
    "df_test = pd.merge(df_test,ct_test, on = 'user_id', how = 'left')\n",
    "\n",
    "# CLEANING AGE AND EXP VALUES\n",
    "df_train['age'] = np.where(((df_train.age < 18)|(df_train.age>65)),np.nan,df_train.age)\n",
    "df_test['age'] = np.where(((df_test.age < 18)|(df_test.age>65)),np.nan,df_test.age)\n",
    "df_train['exp'] = np.where(((df_train.exp < 0)|(df_train.exp>47)),np.nan,df_train.exp)\n",
    "df_test['exp'] = np.where(((df_test.exp < 0)|(df_test.exp>47)),np.nan,df_test.exp)\n",
    "df_train = df_train.dropna(axis = 'rows', subset = ['age','exp'])\n",
    "df_test = df_test.dropna(axis = 'rows', subset = ['age','exp'])\n",
    "df_train = df_train.fillna('NaN')\n",
    "df_test = df_test.fillna('NaN')\n",
    "\n",
    "# CONVERTING OBJECT TYPES TO FLOAT\n",
    "for i in ['years_since_last_ride','rents_count', 'bill_total','last_month_ride', 'avg_week_rents']:\n",
    "    df_train[i] = df_train[i].replace('NaN',np.nan)\n",
    "for i in ['years_since_last_ride','rents_count', 'bill_total','last_month_ride', 'avg_week_rents']:\n",
    "    df_test[i] = df_test[i].replace('NaN',np.nan)\n",
    "df_train = df_train.dropna(axis = 'rows', subset = ['years_since_activation','years_since_last_ride','rents_count',\\\n",
    "                                                'bill_total','last_month_ride', 'avg_week_rents'])\n",
    "df_test = df_test.dropna(axis = 'rows', subset = ['years_since_activation','years_since_last_ride','rents_count',\\\n",
    "                                                'bill_total','last_month_ride', 'avg_week_rents'])\n",
    "df_train.reset_index(drop = True, inplace = True)\n",
    "df_test.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# CALCULATING % OF PAID AGREEMENT INVOICES\n",
    "def target_calc(df, paid_invoices_sum, invoices_sum, non_binary_column_name, binary_column_name):\n",
    "    df[non_binary_column_name] = df[paid_invoices_sum]/df[invoices_sum]\n",
    "    df[non_binary_column_name] = df[[non_binary_column_name,'1']].min(axis=1)\n",
    "    df[binary_column_name] = np.where(df[non_binary_column_name] == 0.0,1,0)\n",
    "\n",
    "df_train['1'] = 1 \n",
    "df_test['1'] = 1\n",
    "for i,e in [['total_invoices_sum', 'total_paid_invoices_sum'],['rent_invoices_sum', 'paid_rent_invoices_sum'],\\\n",
    "            ['camera_invoices_sum', 'paid_camera_invoices_sum'],['agreement_invoices_sum', 'paid_agreement_invoices_sum'],\\\n",
    "            ['accident_invoices_sum', 'paid_accident_invoices_sum'],['other_invoices_sum', 'paid_other_invoices_sum'],\\\n",
    "            ['agreement_accident_invoices_sum', 'paid_agreement_accident_invoices_sum'],\\\n",
    "            ['agreement_STD_invoices_sum','paid_agreement_STD_invoices_sum'],\\\n",
    "            ['agreement_evacuation_invoices_sum', 'paid_agreement_evacuation_invoices_sum'],\\\n",
    "            ['agreement_new_injuries_invoices_sum', 'paid_agreement_new_injuries_invoices_sum'],\\\n",
    "            ['agreement_other_invoices_sum', 'paid_agreement_other_invoices_sum']]:\n",
    "    target_calc(df_train, e, i, '%_'+e, i[:-4]+'_no_payment')\n",
    "    target_calc(df_test, e, i, '%_'+e, i[:-4]+'_no_payment')\n",
    "df_train = df_train.drop('1',1)\n",
    "df_test = df_test.drop('1',1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### PREPARING AND ORGANIZING CATEGORICAL DATAFRAMES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING DEVICES DATAFRAME\n",
    "devices_lib = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/devices_lib.csv')\n",
    "user_devices = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/user_devices.csv')\n",
    "user_devices = pd.merge(user_devices, devices_lib, left_on = 'device_type', right_on = 'device', how = 'left')\n",
    "user_devices = user_devices[['user_id', 'device_type', 'brand', 'device_gen', 'branded_gen_grouped', 'gen_grouped']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING KBM DATAFRAME\n",
    "kbm = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/user_kbm.csv')\n",
    "kbm = kbm[['user_id', 'kbm']]\n",
    "kbm['kbm_grouped'] = np.where(kbm['kbm']<0.7,'0.5+',\\\n",
    "                              np.where(kbm['kbm']<0.8,'0.7+',\\\n",
    "                                       np.where(kbm['kbm']<0.9,'0.8+',\\\n",
    "                                                np.where(kbm['kbm']<1,'0.9+',\\\n",
    "                                                         np.where(kbm['kbm'] == 1, '1',\\\n",
    "                                                                  np.where(kbm['kbm']<2.3,'1.4+',\\\n",
    "                                                                           np.where(kbm['kbm']>=2.3,'2.3+',np.nan)))))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING BIRTH PLACE REGION DATAFRAME\n",
    "bp = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/birthplaces_lib.csv')\n",
    "bp = bp[['PassportBirthPlace','country','region']]\n",
    "bp = bp.replace('None', np.nan)\n",
    "bp = bp.dropna(axis='rows')\n",
    "bp = bp.drop_duplicates(subset = ['PassportBirthPlace'])\n",
    "\n",
    "# BIRTH PLACES LIB\n",
    "bp_clsfied = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/birthplaces_classified_lib.csv')\n",
    "\n",
    "# COUNTRIES\n",
    "countries = bp_clsfied.drop_duplicates(subset = 'bp_country')\n",
    "countries = pd.concat([countries.iloc[1:2],countries.iloc[3:]], axis='rows')\n",
    "countries = countries[['bp_country', 'bp_region_group_detailed']]\n",
    "\n",
    "# MERGING\n",
    "bp = pd.merge(bp, bp_clsfied, left_on = 'region', right_on = 'bp_region_group_detailed', how = 'left')\n",
    "bp = pd.merge(bp, countries, left_on = 'country', right_on = 'bp_country', how = 'left')\n",
    "\n",
    "bp['bp_region_group_detailed'] = np.where(pd.isnull(bp.bp_region_group_detailed_x) == True,bp.bp_region_group_detailed_y,\\\n",
    "                                            bp.bp_region_group_detailed_x)\n",
    "bp = bp[['PassportBirthPlace', 'bp_region_group_detailed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING MOBILE OPERATORS DATAFRAME\n",
    "mob = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/mobile_codes_lib.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING LICENSE CATEGORY DATAFRAME\n",
    "lcns = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/license_cat_lib.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING PASSPORT REGION DATAFRAME\n",
    "psp_region = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/psp_regions_codes_lib.csv')\n",
    "psp_region['psp_region_code'] = psp_region['psp_dep_region_code'].str.replace('<','')\n",
    "psp_region['psp_region_code'] = psp_region['psp_region_code'].str.replace('>','')\n",
    "psp_region = psp_region[['psp_region_code', 'psp_region', 'psp_fed_district']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING SCORING DATAFRAME\n",
    "scr = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/users_deli_scores_lib.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ENRICHING ORIGINAL DATAFRAME WITH CLASSIFIED CATEGORICAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# DATA ENRICHMENT\n",
    "df_train = pd.merge(df_train, user_devices, on = 'user_id', how = 'left')\n",
    "df_train = pd.merge(df_train, kbm, on = 'user_id', how = 'left')\n",
    "df_train = pd.merge(df_train, bp, left_on = 'birth_place', right_on = 'PassportBirthPlace', how = 'left')\n",
    "df_train = pd.merge(df_train, mob, on = 'mobile_code', how = 'left')\n",
    "df_train = pd.merge(df_train, lcns, on = 'license_category', how = 'left')\n",
    "\n",
    "df_test = pd.merge(df_test, user_devices, on = 'user_id', how = 'left')\n",
    "df_test = pd.merge(df_test, kbm, on = 'user_id', how = 'left')\n",
    "df_test = pd.merge(df_test, bp, left_on = 'birth_place', right_on = 'PassportBirthPlace', how = 'left')\n",
    "df_test = pd.merge(df_test, mob, on = 'mobile_code', how = 'left')\n",
    "df_test = pd.merge(df_test, lcns, on = 'license_category', how = 'left')\n",
    "\n",
    "# # SIMPLE MODIFICATION OF SOME VARIABLES\n",
    "df_train['PassportDepartmentRegionCode'] = df_train['PassportDepartmentCode'].str[:2]\n",
    "df_test['PassportDepartmentRegionCode'] = df_test['PassportDepartmentCode'].str[:2]\n",
    "\n",
    "# # DATA ENRICHMENT CONTINUED\n",
    "df_train = pd.merge(df_train, psp_region, left_on = 'PassportDepartmentRegionCode', right_on = 'psp_region_code', how = 'left')\n",
    "df_test = pd.merge(df_test, psp_region, left_on = 'PassportDepartmentRegionCode', right_on = 'psp_region_code', how = 'left')\n",
    "df_train = pd.merge(df_train, scr, on = 'user_id', how = 'left')\n",
    "df_test = pd.merge(df_test, scr, on = 'user_id', how = 'left')\n",
    "\n",
    "# REPLACE ALL NAN VALUES WITH STRING TYPE NAN FOR REGRESSION\n",
    "df_train = df_train.fillna('NaN')\n",
    "df_test = df_test.fillna('NaN')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SPLITTING USER'S DATA INTO TWO CATEGORIES: REGISTRATIONAL AND SERVICE USAGE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SPLITTING USER'S DATA INTO TWO CATEGORIES: REGISTRATIONAL AND SERVICE USAGE\n",
    "reg_cols = ['user_id', 'mobile_operator', 'brand', 'branded_gen_grouped', 'gen_grouped','age',\\\n",
    "            'exp', 'bp_region_group_detailed', 'country', 'sex', 'region_name_en', 'license_category_grouped',\\\n",
    "            'kbm_grouped', 'PassportRegistration','psp_region', 'psp_fed_district']\n",
    "service_usage_cols = ['user_id','years_since_registration', 'years_since_activation', 'years_since_last_ride', 'rents_count',\\\n",
    "                      'bill_total', 'bonus_total', 'last_month_ride', 'avg_week_rents', 'tariff','DrivingStyle_delimobilScore']\n",
    "target_cols = list(df_train.columns[81:102])\n",
    "\n",
    "df_usg_train = df_train[reg_cols+service_usage_cols+target_cols]\n",
    "df_usg_test = df_test[reg_cols+service_usage_cols+target_cols]\n",
    "\n",
    "# SAVING PROCESSED DATASETS\n",
    "df_usg_train.to_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_usg_data_train.csv',index=False,\\\n",
    "                    encoding='utf-8-sig')\n",
    "df_usg_test.to_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_usg_data_test.csv',index=False,\\\n",
    "                    encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### EXPLANATORY ANALYSIS OF THE REGISTRATIONAL DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>%_paid_accident_invoices</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gen_grouped</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>last</th>\n",
       "      <td>0.767647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>previous</th>\n",
       "      <td>0.513073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>before previous</th>\n",
       "      <td>0.471736</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>old</th>\n",
       "      <td>0.319628</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>other</th>\n",
       "      <td>0.290546</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 %_paid_accident_invoices\n",
       "gen_grouped                              \n",
       "last                             0.767647\n",
       "previous                         0.513073\n",
       "before previous                  0.471736\n",
       "old                              0.319628\n",
       "other                            0.290546"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# EXPLANATORY ANALYSIS OF THE REGISTRATIONAL DATA\n",
    "def groupby_algo(df,column,column_to_calc):\n",
    "    grpd = df.groupby(column).sum()\n",
    "    grpd[column_to_calc] = grpd['paid_accident_invoices_sum']/grpd['accident_invoices_sum']\n",
    "    grpd = grpd[[column_to_calc]]\n",
    "    grpd = grpd.sort_values(by = column_to_calc, ascending = False, na_position = 'first')\n",
    "#     grpd = grpd.sort_values(by = column, ascending = True, na_position = 'first') # NUMBER-SPECIFIC LINE\n",
    "    if len(grpd.index) > 10:\n",
    "        with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "            print(grpd)\n",
    "            plt.plot(grpd)\n",
    "    else:\n",
    "        return grpd\n",
    "        plt.plot(grpd)\n",
    "\n",
    "groupby_algo(df_reg, 'gen_grouped', '%_paid_accident_invoices')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SAVING DATASETS WITH NO NAN VALUES\n",
    "df_reg_notna = df_reg[df_reg['bp_region_group_detailed'].notna()]\n",
    "df_reg_notna.to_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_reg_notna_data.csv',\\\n",
    "                    index=False, encoding='utf-8-sig')\n",
    "\n",
    "# REMOVING NAN DATA FROM THE DATASET\n",
    "df_reg_notna_agrmnt = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_reg_notna_agrmnt_data.csv')\n",
    "df_reg_notna_agrmnt = df_reg_notna_agrmnt[df_reg_notna_agrmnt['agreement_invoices_sum'].notna()]\n",
    "df_reg_notna_agrmnt.to_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_reg_notna_agrmnt_data.csv',\\\n",
    "                           index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LIMITING % OF PAID INVOICES WITH 100%\n",
    "agrmnt['1'] = 1\n",
    "agrmnt['%_paid_agreement_invoices'] = agrmnt[['1','%_paid_agreement_invoices']].min(axis=1)\n",
    "agrmnt = agrmnt.drop('1',1)\n",
    "agrmnt.info(verbose = True, null_counts = True)\n",
    "agrmnt.to_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_reg_notna_agrmnt_data.csv',\\\n",
    "              index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING LINEAR REGRESSION ON THE INVOICE LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# UPLOADING AGREEMENT INVOICES DATA\n",
    "agrmnt = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_reg_notna_agrmnt_data.csv')\n",
    "\n",
    "# CHECKING FOR MULTICOLLINEARITY\n",
    "corrMatrix_df = agrmnt[list(agrmnt.columns[9:16])+list(agrmnt.columns[17:18])+list(agrmnt.columns[25:119])]\n",
    "corrMatrix = corrMatrix_df.corr()\n",
    "corrMatrix.to_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/corrMatrix.csv', index=False, encoding='utf-8-sig')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                    OLS Regression Results                                    \n",
      "==============================================================================================\n",
      "Dep. Variable:     %_paid_agreement_invoices   R-squared (uncentered):                   0.792\n",
      "Model:                                   OLS   Adj. R-squared (uncentered):              0.791\n",
      "Method:                        Least Squares   F-statistic:                              1268.\n",
      "Date:                       Tue, 17 Nov 2020   Prob (F-statistic):                        0.00\n",
      "Time:                               18:26:12   Log-Likelihood:                         -16116.\n",
      "No. Observations:                      34141   AIC:                                  3.244e+04\n",
      "Df Residuals:                          34039   BIC:                                  3.330e+04\n",
      "Df Model:                                102                                                  \n",
      "Covariance Type:                   nonrobust                                                  \n",
      "=====================================================================================================\n",
      "                                        coef    std err          t      P>|t|      [0.025      0.975]\n",
      "-----------------------------------------------------------------------------------------------------\n",
      "mobile_operator_encoded              -0.0382      0.006     -6.360      0.000      -0.050      -0.026\n",
      "sex_encoded                           0.0069      0.006      1.235      0.217      -0.004       0.018\n",
      "last                                  0.1856      0.030      6.229      0.000       0.127       0.244\n",
      "previous                              0.1272      0.007     17.810      0.000       0.113       0.141\n",
      "before previous                       0.0818      0.006     13.870      0.000       0.070       0.093\n",
      "old                                   0.0081      0.005      1.536      0.125      -0.002       0.018\n",
      "age_grouped.1                         0.0002      0.000      0.817      0.414      -0.000       0.001\n",
      "Курская область                       0.7562      0.032     23.852      0.000       0.694       0.818\n",
      "Ярославская область                   0.8133      0.043     18.908      0.000       0.729       0.898\n",
      "Республика Дагестан                   0.6724      0.018     37.955      0.000       0.638       0.707\n",
      "Азербайджан                           0.6746      0.018     38.212      0.000       0.640       0.709\n",
      "Московская область                    0.7958      0.014     56.175      0.000       0.768       0.824\n",
      "Москва                                0.7800      0.012     63.697      0.000       0.756       0.804\n",
      "Омская область                        0.7473      0.027     27.888      0.000       0.695       0.800\n",
      "Ямало-Ненецкий автономный округ       0.7275      0.039     18.881      0.000       0.652       0.803\n",
      "Республика Башкортостан               0.7077      0.020     35.560      0.000       0.669       0.747\n",
      "Украина                               0.7815      0.020     39.757      0.000       0.743       0.820\n",
      "Челябинская область                   0.7287      0.024     30.457      0.000       0.682       0.776\n",
      "Хабаровский край                      0.7835      0.030     26.093      0.000       0.725       0.842\n",
      "Брянская область                      0.8275      0.027     30.444      0.000       0.774       0.881\n",
      "Республика Ингушетия                  0.6790      0.045     15.070      0.000       0.591       0.767\n",
      "Ульяновская область                   0.7598      0.029     25.802      0.000       0.702       0.818\n",
      "Ленинградская область                 0.7264      0.021     33.995      0.000       0.684       0.768\n",
      "Свердловская область                  0.6809      0.016     42.394      0.000       0.649       0.712\n",
      "Краснодарский край                    0.6319      0.017     37.830      0.000       0.599       0.665\n",
      "Кабардино-Балкарская Республика       0.7076      0.022     32.364      0.000       0.665       0.750\n",
      "Самарская область                     0.6746      0.020     33.430      0.000       0.635       0.714\n",
      "Смоленская область                    0.8365      0.030     27.576      0.000       0.777       0.896\n",
      "Белгородская область                  0.7528      0.033     23.027      0.000       0.689       0.817\n",
      "Армения                               0.7099      0.022     32.494      0.000       0.667       0.753\n",
      "Казахстан                             0.7954      0.021     38.775      0.000       0.755       0.836\n",
      "Ставропольский край                   0.7443      0.019     38.243      0.000       0.706       0.782\n",
      "Иркутская область                     0.8040      0.026     31.469      0.000       0.754       0.854\n",
      "Республика Северная Осетия-Алания     0.7516      0.026     28.858      0.000       0.701       0.803\n",
      "Пензенская область                    0.7956      0.033     24.197      0.000       0.731       0.860\n",
      "Таджикистан                           0.7890      0.023     33.807      0.000       0.743       0.835\n",
      "Тюменская область                     0.7026      0.037     18.772      0.000       0.629       0.776\n",
      "Узбекистан                            0.7831      0.022     35.650      0.000       0.740       0.826\n",
      "Республика Коми                       0.7256      0.031     23.645      0.000       0.665       0.786\n",
      "Воронежская область                   0.7777      0.029     26.825      0.000       0.721       0.835\n",
      "Остальной мир                         0.8145      0.029     28.514      0.000       0.759       0.870\n",
      "Красноярский край                     0.7139      0.023     31.171      0.000       0.669       0.759\n",
      "Астраханская область                  0.7202      0.031     23.602      0.000       0.660       0.780\n",
      "Удмуртская Республика                 0.7846      0.033     23.568      0.000       0.719       0.850\n",
      "Новосибирская область                 0.6935      0.020     34.161      0.000       0.654       0.733\n",
      "Республика Карелия                    0.6915      0.042     16.369      0.000       0.609       0.774\n",
      "Волгоградская область                 0.7339      0.022     33.378      0.000       0.691       0.777\n",
      "Курганская область                    0.6679      0.039     17.299      0.000       0.592       0.744\n",
      "Республика Калмыкия                   0.7214      0.035     20.674      0.000       0.653       0.790\n",
      "Липецкая область                      0.7484      0.034     21.973      0.000       0.682       0.815\n",
      "Республика Татарстан                  0.7316      0.025     29.710      0.000       0.683       0.780\n",
      "Молдавия                              0.7691      0.029     26.862      0.000       0.713       0.825\n",
      "Нижегородская область                 0.6874      0.019     35.826      0.000       0.650       0.725\n",
      "Ростовская область                    0.6871      0.017     39.434      0.000       0.653       0.721\n",
      "Тамбовская область                    0.7589      0.029     25.870      0.000       0.701       0.816\n",
      "Алтайский край                        0.7518      0.030     25.311      0.000       0.694       0.810\n",
      "Саратовская область                   0.7438      0.023     32.364      0.000       0.699       0.789\n",
      "Беларусь                              0.7751      0.034     22.740      0.000       0.708       0.842\n",
      "Приморский край                       0.7464      0.030     25.191      0.000       0.688       0.804\n",
      "Чувашская Республика                  0.7635      0.025     30.060      0.000       0.714       0.813\n",
      "Туркменистан                          0.7410      0.045     16.515      0.000       0.653       0.829\n",
      "Республика Саха (Якутия)              0.7875      0.034     22.942      0.000       0.720       0.855\n",
      "Тульская область                      0.7782      0.020     39.380      0.000       0.740       0.817\n",
      "Сахалинская область                   0.7780      0.041     18.759      0.000       0.697       0.859\n",
      "Кировская область                     0.8096      0.029     27.563      0.000       0.752       0.867\n",
      "Калининградская область               0.7409      0.038     19.556      0.000       0.667       0.815\n",
      "Кемеровская область                   0.7513      0.024     30.762      0.000       0.703       0.799\n",
      "Оренбургская область                  0.7580      0.024     31.293      0.000       0.711       0.806\n",
      "Пермский край                         0.7668      0.028     27.109      0.000       0.711       0.822\n",
      "Псковская область                     0.7342      0.040     18.364      0.000       0.656       0.813\n",
      "Киргизия                              0.8173      0.027     29.918      0.000       0.764       0.871\n",
      "Мурманская область                    0.7907      0.028     28.498      0.000       0.736       0.845\n",
      "Орловская область                     0.7326      0.043     16.976      0.000       0.648       0.817\n",
      "Ивановская область                    0.7983      0.036     22.370      0.000       0.728       0.868\n",
      "Владимирская область                  0.8039      0.027     29.896      0.000       0.751       0.857\n",
      "Костромская область                   0.7615      0.052     14.704      0.000       0.660       0.863\n",
      "Калужская область                     0.7461      0.031     23.802      0.000       0.685       0.808\n",
      "Чеченская Республика                  0.6498      0.023     28.325      0.000       0.605       0.695\n",
      "Карачаево-Черкесская Республика       0.8154      0.039     21.050      0.000       0.739       0.891\n",
      "Грузия                                0.7089      0.027     26.020      0.000       0.655       0.762\n",
      "Тверская область                      0.7713      0.027     28.059      0.000       0.717       0.825\n",
      "Литва                                 0.7676      0.086      8.964      0.000       0.600       0.935\n",
      "Забайкальский край                    0.7447      0.039     19.331      0.000       0.669       0.820\n",
      "Рязанская область                     0.7745      0.035     21.899      0.000       0.705       0.844\n",
      "Томская область                       0.7610      0.039     19.714      0.000       0.685       0.837\n",
      "Вологодская область                   0.7524      0.035     21.789      0.000       0.685       0.820\n",
      "Республика Мордовия                   0.7607      0.030     24.972      0.000       0.701       0.820\n",
      "Амурская область                      0.7314      0.037     19.576      0.000       0.658       0.805\n",
      "Республика Хакасия                    0.7320      0.055     13.357      0.000       0.625       0.839\n",
      "Магаданская область                   0.6970      0.047     14.757      0.000       0.604       0.790\n",
      "Республика Бурятия                    0.6919      0.041     16.713      0.000       0.611       0.773\n",
      "Архангельская область                 0.7417      0.029     26.011      0.000       0.686       0.798\n",
      "Камчатский край                       0.8027      0.042     19.097      0.000       0.720       0.885\n",
      "Республика Адыгея                     0.6313      0.056     11.367      0.000       0.522       0.740\n",
      "Новгородская область                  0.7560      0.042     17.994      0.000       0.674       0.838\n",
      "Респу́блика Тыва́                     0.8514      0.074     11.477      0.000       0.706       0.997\n",
      "Санкт-Петербург                       0.7064      0.174      4.056      0.000       0.365       1.048\n",
      "Республика Марий Эл                   0.7633      0.050     15.405      0.000       0.666       0.860\n",
      "Чукотский автономный округ            0.7965      0.077     10.316      0.000       0.645       0.948\n",
      "Еврейская автономная область          0.9899      0.138      7.181      0.000       0.720       1.260\n",
      "Ненецкий автономный округ             0.8032      0.195      4.128      0.000       0.422       1.185\n",
      "agreement_invoices_sum            -2.248e-06   3.95e-08    -56.930      0.000   -2.33e-06   -2.17e-06\n",
      "==============================================================================\n",
      "Omnibus:                     4125.677   Durbin-Watson:                   1.807\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):             5804.696\n",
      "Skew:                          -1.002   Prob(JB):                         0.00\n",
      "Kurtosis:                       3.256   Cond. No.                     5.36e+06\n",
      "==============================================================================\n",
      "\n",
      "Warnings:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The condition number is large, 5.36e+06. This might indicate that there are\n",
      "strong multicollinearity or other numerical problems.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3213657618802598\n"
     ]
    }
   ],
   "source": [
    "# OLS LINEAR REGRESSION\n",
    "X = agrmnt[list(agrmnt.columns[9:16])+list(agrmnt.columns[25:119])+list(agrmnt.columns[121:122])]\n",
    "y = agrmnt['%_paid_agreement_invoices']\n",
    "model = sm.OLS(y, X).fit()\n",
    "print(model.summary())\n",
    "\n",
    "# WRITING DOWN PREDICTION VALUES\n",
    "prediction = model.predict(X)\n",
    "agrmnt['lin_prediction'] = prediction\n",
    "agrmnt.to_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/vis_analysis.csv', index=False, encoding='utf-8-sig')\n",
    "\n",
    "# CALCULATING RMSE\n",
    "print(mean_absolute_error(y, prediction))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\indexing.py:671: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self._setitem_with_indexer(indexer, value)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.614887\n",
       "1    0.391227\n",
       "2    0.982487\n",
       "3    0.758827\n",
       "dtype: float64"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# TESTING PREDICTION ON RANDOM VALUES\n",
    "X_pred = X.iloc[0:0]\n",
    "d1 = dict(zip(list(X.columns),[1,1,0,0,0,1,18]+[0]*5+[1]+[0]*88+[500]))\n",
    "X_pred.loc[0] = [1,0,0,0,0,0,18]+[0]*70+[1]+[0]*23+[500] #TELE2;FEMALE;OTHER PHONE MODEL;18;CHECHEN;500\n",
    "X_pred.loc[1] = [1,0,0,0,0,0,18]+[0]*70+[1]+[0]*23+[100000] #TELE2;FEMALE;OTHER PHONE MODEL;18;CHECHEN;100000\n",
    "X_pred.loc[2] = [0,1,1,0,0,0,45]+[0]*5+[1]+[0]*88+[500] #NOT TELE2;MALE;LAST PHONE MODEL;45;MOSCOW;500\n",
    "X_pred.loc[3] = [0,1,1,0,0,0,45]+[0]*5+[1]+[0]*88+[100000] #NOT TELE2;MALE;LAST PHONE MODEL;45;MOSCOW;100000\n",
    "prediction = model.predict(X_pred)\n",
    "prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING LOGISTIC REGRESSION ON THE USER LEVEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   11.5s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   20.3s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    9.9s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   10.4s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   12.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.4027680277974213 0.6540949245271162\n"
     ]
    }
   ],
   "source": [
    "# CONVERTING % VALUES INTO BOOLEAN\n",
    "df_reg['default_user'] = np.where(df_reg['%_paid_agreement_invoices_sum'] == 0.0,1,0)\n",
    "\n",
    "# DEFINING X AND Y\n",
    "X = df_reg[['mobile_operator','sex', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'kbm_grouped',\\\n",
    "            'license_category_grouped']]\n",
    "X = X.fillna('NaN')\n",
    "y = df_reg['default_user']\n",
    "\n",
    "# ONE-HOT ENCODING VARIABLES\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), ['mobile_operator', 'sex', 'gen_grouped', 'bp_region_group_detailed','kbm_grouped',\\\n",
    "                       'license_category_grouped']), remainder='passthrough')\n",
    "\n",
    "# PIPELINE (BY DATA SCHOOL)\n",
    "logreg = LogisticRegression(solver = 'lbfgs', class_weight = 'balanced', max_iter = 100, verbose = True)\n",
    "pipe = make_pipeline(column_trans, logreg)\n",
    "cross_val_score(pipe, X, y, cv = 5, scoring = 'accuracy').mean()\n",
    "\n",
    "# PIPELINE (BY SCIKIT)\n",
    "model = make_pipeline(column_trans, logreg)\n",
    "_ = model.fit(X,y)\n",
    "y_pred = model.predict(X)\n",
    "mae = mean_absolute_error(y,y_pred)\n",
    "roc_auc = roc_auc_score(y,y_pred)\n",
    "print(mae, roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING LOGISTIC REGRESSION ON REG DATA WITH QIWI SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%_total_paid_invoices_sum ; w/o Qiwi ; train: 0.6116973436112371 ; test: 0.5777334667820261\n",
      "%_total_paid_invoices_sum ; with Qiwi ; train: 0.5784054007165509 ; test: 0.6088874786329364\n",
      "%_paid_rent_invoices_sum ; w/o Qiwi ; train: 0.7065351353472977 ; test: 0.6972932223048834\n",
      "%_paid_rent_invoices_sum ; with Qiwi ; train: 0.6703830101577148 ; test: 0.7372163768931715\n",
      "%_paid_camera_invoices_sum ; w/o Qiwi ; train: 0.7282131023408951 ; test: 0.6659142346634901\n",
      "%_paid_camera_invoices_sum ; with Qiwi ; train: 0.6778521949639347 ; test: 0.75248470409876\n",
      "%_paid_agreement_invoices_sum ; w/o Qiwi ; train: 0.6580193362683782 ; test: 0.6356161786185117\n",
      "%_paid_agreement_invoices_sum ; with Qiwi ; train: 0.640896640584613 ; test: 0.6449192619731787\n",
      "%_paid_accident_invoices_sum ; w/o Qiwi ; train: 0.7506210276690591 ; test: 0.6448898294535044\n",
      "%_paid_accident_invoices_sum ; with Qiwi ; train: 0.6184935969194113 ; test: 0.6588765093987302\n",
      "%_paid_other_invoices_sum ; w/o Qiwi ; train: 0.5487402002800773 ; test: 0.545809495441247\n",
      "%_paid_other_invoices_sum ; with Qiwi ; train: 0.5330229143657044 ; test: 0.5312090097315265\n",
      "%_paid_agreement_accident_invoices_sum ; w/o Qiwi ; train: 0.7185336612288851 ; test: 0.6502490864022351\n",
      "%_paid_agreement_accident_invoices_sum ; with Qiwi ; train: 0.6228484494053759 ; test: 0.6538800236883111\n",
      "%_paid_agreement_STD_invoices_sum ; w/o Qiwi ; train: 0.6711772746040711 ; test: 0.5524697144523655\n",
      "%_paid_agreement_STD_invoices_sum ; with Qiwi ; train: 0.6158763512049118 ; test: 0.6575891317016761\n",
      "%_paid_agreement_evacuation_invoices_sum ; w/o Qiwi ; train: 0.802825567866706 ; test: 0.6193577677149755\n",
      "%_paid_agreement_evacuation_invoices_sum ; with Qiwi ; train: 0.6511036355911228 ; test: 0.5733221528028577\n",
      "%_paid_agreement_new_injuries_invoices_sum ; w/o Qiwi ; train: 0.6953868492156172 ; test: 0.641602112560073\n",
      "%_paid_agreement_new_injuries_invoices_sum ; with Qiwi ; train: 0.6128912354358653 ; test: 0.5882914483067568\n",
      "%_paid_agreement_other_invoices_sum ; w/o Qiwi ; train: 0.6842173810032832 ; test: 0.627806159068669\n",
      "%_paid_agreement_other_invoices_sum ; with Qiwi ; train: 0.6566586984567784 ; test: 0.6542321399206907\n"
     ]
    }
   ],
   "source": [
    "# LOADING df_reg_qiwi DATAFRAME\n",
    "df_reg = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_reg_data.csv', low_memory = False)\n",
    "\n",
    "# UPLOADING QIWI RESULTS\n",
    "qiwi = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/QIWI_test/deli_results_23112020.csv')\n",
    "\n",
    "# ADDING GROUP NAME TO THE QIWI DATASET\n",
    "group_name = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/QIWI_test/qiwi_exp_full.csv')\n",
    "group_name['ID'] = group_name['id']\n",
    "group_name = group_name[['ID', 'group_name']]\n",
    "\n",
    "# MERGING GROUP NAME WITH THE QIWI DATASET\n",
    "qiwi = pd.merge(qiwi, group_name, on = 'ID', how = 'left')\n",
    "\n",
    "# MERGING QIWI DATASET WITH REGISTRATIONAL DATA\n",
    "df_reg_qiwi = pd.merge(df_reg, qiwi, left_on = 'user_id', right_on = 'ID', how = 'left')\n",
    "df_reg_qiwi= df_reg_qiwi.loc[pd.isnull(df_reg_qiwi['ID']) == False]\n",
    "\n",
    "# DEFINING X AND Y\n",
    "X = df_reg_qiwi[['mobile_operator','sex', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'kbm_grouped',\\\n",
    "                 'license_category_grouped']]\n",
    "X = X.fillna('NaN')\n",
    "\n",
    "# Xq = df_reg_qiwi[['mobile_operator','sex', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'kbm_grouped',\\\n",
    "#             'license_category_grouped', 'pd_basis_60_v3_4']]\n",
    "Xq = df_reg_qiwi[['pd_basis_60_v3_4']]\n",
    "Xq = Xq.fillna('NaN')\n",
    "\n",
    "for target in ['%_total_paid_invoices_sum','%_paid_rent_invoices_sum','%_paid_camera_invoices_sum',\\\n",
    "               '%_paid_agreement_invoices_sum','%_paid_accident_invoices_sum','%_paid_other_invoices_sum',\\\n",
    "               '%_paid_agreement_accident_invoices_sum','%_paid_agreement_STD_invoices_sum',\\\n",
    "               '%_paid_agreement_evacuation_invoices_sum','%_paid_agreement_new_injuries_invoices_sum',\\\n",
    "               '%_paid_agreement_other_invoices_sum']:\n",
    "    \n",
    "    # CONVERTING % VALUES INTO BOOLEAN\n",
    "    df_reg_qiwi['default_user'] = np.where(df_reg_qiwi[target] == 0.0,1,0)                  \n",
    "    y = df_reg_qiwi['default_user']\n",
    "    \n",
    "    # RUNNING LOOP\n",
    "    for x, name in [(X,'w/o Qiwi'),(Xq, 'with Qiwi')]:\n",
    "        \n",
    "        # SPLITTING DATASET INTO TRAIN AND TEST SAMPLES\n",
    "        x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "        \n",
    "        # ONE-HOT ENCODING VARIABLES\n",
    "#         column_trans = make_column_transformer((StandardScaler(), list(x_train.loc[:, x_train.dtypes == float].columns)),\n",
    "#                                                (OneHotEncoder(), ['mobile_operator', 'sex', 'gen_grouped', \\\n",
    "#                                                                   'bp_region_group_detailed','kbm_grouped',\\\n",
    "#                                                                   'license_category_grouped']),remainder = 'passthrough')\n",
    "        column_trans = make_column_transformer((StandardScaler(), list(x_train.loc[:, x_train.dtypes == float].columns)),\n",
    "                                               (OneHotEncoder(), list(x_train.loc[:, x_train.dtypes == object])),\\\n",
    "                                                remainder = 'passthrough')\n",
    "        # PIPELINE SET UP\n",
    "        logreg = LogisticRegression(solver = 'lbfgs', class_weight = 'balanced', max_iter = 1000)\n",
    "        model = make_pipeline(column_trans, logreg)\n",
    "        _ = model.fit(x_train,y_train)\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        y_pred_test = model.predict(x_test)\n",
    "        roc_auc_train = roc_auc_score(y_train,y_pred_train)\n",
    "        roc_auc_test = roc_auc_score(y_test,y_pred_test)\n",
    "        print(target,';',name,';','train:',roc_auc_train,';','test:',roc_auc_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING LOGISTIC REGRESSION ON USAGE DATA WITH QIWI SCORING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%_total_paid_invoices_sum ; w/o Qiwi ; train: 0.7522814349586708 ; test: 0.5994648555043649\n",
      "%_total_paid_invoices_sum ; with Qiwi ; train: 0.7576429871712687 ; test: 0.6050226764997059\n",
      "%_paid_rent_invoices_sum ; w/o Qiwi ; train: 0.9193298019738192 ; test: 0.568996918703648\n",
      "%_paid_rent_invoices_sum ; with Qiwi ; train: 0.9229444369979644 ; test: 0.5923893005856024\n",
      "%_paid_camera_invoices_sum ; w/o Qiwi ; train: 0.9236030722693052 ; test: 0.668369314990077\n",
      "%_paid_camera_invoices_sum ; with Qiwi ; train: 0.9308713183480419 ; test: 0.6822827180304165\n",
      "%_paid_agreement_invoices_sum ; w/o Qiwi ; train: 0.8080870497756558 ; test: 0.6899127193282363\n",
      "%_paid_agreement_invoices_sum ; with Qiwi ; train: 0.8137597607142847 ; test: 0.6939529810808518\n",
      "%_paid_accident_invoices_sum ; w/o Qiwi ; train: 0.879028320432273 ; test: 0.7270074284081668\n",
      "%_paid_accident_invoices_sum ; with Qiwi ; train: 0.8822009417370377 ; test: 0.7495406694358366\n",
      "%_paid_other_invoices_sum ; w/o Qiwi ; train: 0.7405153871684282 ; test: 0.6338098418375885\n",
      "%_paid_other_invoices_sum ; with Qiwi ; train: 0.740596805794415 ; test: 0.6337431898248832\n",
      "%_paid_agreement_accident_invoices_sum ; w/o Qiwi ; train: 0.8708722474509468 ; test: 0.7209488802443903\n",
      "%_paid_agreement_accident_invoices_sum ; with Qiwi ; train: 0.8717810935530068 ; test: 0.7398218720467682\n",
      "%_paid_agreement_STD_invoices_sum ; w/o Qiwi ; train: 0.7979458827385191 ; test: 0.5817294126129171\n",
      "%_paid_agreement_STD_invoices_sum ; with Qiwi ; train: 0.7939180270530563 ; test: 0.5715792934648167\n",
      "%_paid_agreement_evacuation_invoices_sum ; w/o Qiwi ; train: 0.9139847727497898 ; test: 0.6579301878547873\n",
      "%_paid_agreement_evacuation_invoices_sum ; with Qiwi ; train: 0.914667114636633 ; test: 0.6488561079748639\n",
      "%_paid_agreement_new_injuries_invoices_sum ; w/o Qiwi ; train: 0.8238464356321048 ; test: 0.6879409044520984\n",
      "%_paid_agreement_new_injuries_invoices_sum ; with Qiwi ; train: 0.8323000120377838 ; test: 0.6953002325203816\n",
      "%_paid_agreement_other_invoices_sum ; w/o Qiwi ; train: 0.8490733626552424 ; test: 0.6991733613103623\n",
      "%_paid_agreement_other_invoices_sum ; with Qiwi ; train: 0.8541455454564917 ; test: 0.7057140724062799\n"
     ]
    }
   ],
   "source": [
    "# LOADING df_reg_qiwi DATAFRAME\n",
    "df_usg_train = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_usg_data_train.csv', low_memory = False)\n",
    "df_usg_test = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/processed_usg_data_test.csv', low_memory = False)\n",
    "\n",
    "# UPLOADING QIWI RESULTS\n",
    "qiwi = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/QIWI_test/deli_results_23112020.csv')\n",
    "\n",
    "# ADDING GROUP NAME TO THE QIWI DATASET\n",
    "group_name = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/QIWI_test/qiwi_exp_full.csv')\n",
    "group_name['ID'] = group_name['id']\n",
    "group_name = group_name[['ID', 'group_name']]\n",
    "\n",
    "# MERGING GROUP NAME WITH THE QIWI DATASET\n",
    "qiwi = pd.merge(qiwi, group_name, on = 'ID', how = 'left')\n",
    "\n",
    "# MERGING QIWI DATASET WITH REGISTRATIONAL DATA\n",
    "df_usg_qiwi_train = pd.merge(df_usg_train, qiwi, left_on = 'user_id', right_on = 'ID', how = 'left')\n",
    "df_usg_qiwi_test = pd.merge(df_usg_test, qiwi, left_on = 'user_id', right_on = 'ID', how = 'left')\n",
    "df_usg_qiwi_train = df_usg_qiwi_train.loc[(pd.isnull(df_usg_qiwi_train['ID']) == False)&(df_usg_qiwi_train.tariff != 'сказка банк')]\n",
    "df_usg_qiwi_test = df_usg_qiwi_test.loc[(pd.isnull(df_usg_qiwi_test['ID']) == False)&(df_usg_qiwi_test.tariff != 'сказка банк')]\n",
    "\n",
    "# DEFINING X AND Y\n",
    "X_train = df_usg_qiwi_train[['mobile_operator', 'brand', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'sex',\\\n",
    "                 'license_category_grouped', 'kbm_grouped', 'psp_region', 'years_since_activation', 'years_since_last_ride',\\\n",
    "                 'rents_count', 'bill_total','last_month_ride', 'avg_week_rents', 'tariff']]\n",
    "X_train = X_train.fillna('NaN')\n",
    "\n",
    "X_test = df_usg_qiwi_test[['mobile_operator', 'brand', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'sex',\\\n",
    "                 'license_category_grouped', 'kbm_grouped', 'psp_region', 'years_since_activation', 'years_since_last_ride',\\\n",
    "                 'rents_count', 'bill_total','last_month_ride', 'avg_week_rents', 'tariff']]\n",
    "X_test = X_test.fillna('NaN')\n",
    "\n",
    "Xq_train = df_usg_qiwi_train[['mobile_operator', 'brand', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'sex',\\\n",
    "                  'license_category_grouped', 'kbm_grouped', 'psp_region', 'years_since_activation', 'years_since_last_ride',\\\n",
    "                  'rents_count', 'bill_total','last_month_ride', 'avg_week_rents', 'tariff', 'pd_basis_60_v3_4']]\n",
    "Xq_train = Xq_train.fillna('NaN')\n",
    "\n",
    "Xq_test = df_usg_qiwi_test[['mobile_operator', 'brand', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'sex',\\\n",
    "                  'license_category_grouped', 'kbm_grouped', 'psp_region', 'years_since_activation', 'years_since_last_ride',\\\n",
    "                  'rents_count', 'bill_total','last_month_ride', 'avg_week_rents', 'tariff', 'pd_basis_60_v3_4']]\n",
    "Xq_test = Xq_test.fillna('NaN')\n",
    "\n",
    "for target in ['%_total_paid_invoices_sum','%_paid_rent_invoices_sum','%_paid_camera_invoices_sum',\\\n",
    "               '%_paid_agreement_invoices_sum','%_paid_accident_invoices_sum','%_paid_other_invoices_sum',\\\n",
    "               '%_paid_agreement_accident_invoices_sum','%_paid_agreement_STD_invoices_sum',\\\n",
    "               '%_paid_agreement_evacuation_invoices_sum','%_paid_agreement_new_injuries_invoices_sum',\\\n",
    "               '%_paid_agreement_other_invoices_sum']:\n",
    "    \n",
    "    # CONVERTING % VALUES INTO BOOLEAN\n",
    "    df_usg_qiwi_train['default_user'] = np.where(df_usg_qiwi_train[target] == 0.0,1,0) \n",
    "    Y_train = df_usg_qiwi_train['default_user']\n",
    "    df_usg_qiwi_test['default_user'] = np.where(df_usg_qiwi_test[target] == 0.0,1,0) \n",
    "    Y_test = df_usg_qiwi_test['default_user']\n",
    "    \n",
    "    # RUNNING LOOP\n",
    "    for x_train, y_train, x_test, y_test, name in [(X_train,Y_train,X_test,Y_test,'w/o Qiwi'),(Xq_train,Y_train,Xq_test,Y_test, 'with Qiwi')]:\n",
    "        \n",
    "        # SPLITTING DATASET INTO TRAIN AND TEST SAMPLES\n",
    "#         x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.33, random_state=42)\n",
    "        \n",
    "        # ONE-HOT ENCODING VARIABLES\n",
    "        column_trans = make_column_transformer((StandardScaler(), list(x_train.loc[:, x_train.dtypes == float].columns)),\n",
    "                                               (OneHotEncoder(), list(x_train.loc[:, x_train.dtypes == object].columns)),\\\n",
    "                                               remainder = 'passthrough')\n",
    "        # PIPELINE SET UP\n",
    "        logreg = LogisticRegression(solver = 'lbfgs', class_weight = 'balanced', max_iter = 1000)\n",
    "        model = make_pipeline(column_trans, logreg)\n",
    "        _ = model.fit(x_train,y_train)\n",
    "        y_pred_train = model.predict(x_train)\n",
    "        y_pred_test = model.predict(x_test)\n",
    "        roc_auc_train = roc_auc_score(y_train,y_pred_train)\n",
    "        roc_auc_test = roc_auc_score(y_test,y_pred_test)\n",
    "        print(target,';',name,';','train:',roc_auc_train,';','test:',roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 931857 entries, 0 to 931856\n",
      "Data columns (total 48 columns):\n",
      " #   Column                                      Non-Null Count   Dtype  \n",
      "---  ------                                      --------------   -----  \n",
      " 0   user_id                                     931857 non-null  int64  \n",
      " 1   mobile_operator                             931857 non-null  object \n",
      " 2   brand                                       931857 non-null  object \n",
      " 3   branded_gen_grouped                         931857 non-null  object \n",
      " 4   gen_grouped                                 931857 non-null  object \n",
      " 5   age                                         931857 non-null  float64\n",
      " 6   exp                                         931857 non-null  float64\n",
      " 7   bp_region_group_detailed                    931857 non-null  object \n",
      " 8   country                                     931857 non-null  object \n",
      " 9   sex                                         931857 non-null  object \n",
      " 10  region_name_en                              931857 non-null  object \n",
      " 11  license_category_grouped                    931857 non-null  object \n",
      " 12  kbm_grouped                                 931857 non-null  object \n",
      " 13  PassportRegistration                        931857 non-null  object \n",
      " 14  psp_region                                  931857 non-null  object \n",
      " 15  psp_fed_district                            931857 non-null  object \n",
      " 16  user_id                                     931857 non-null  int64  \n",
      " 17  years_since_registration                    931857 non-null  float64\n",
      " 18  years_since_activation                      931857 non-null  float64\n",
      " 19  years_since_last_ride                       931857 non-null  float64\n",
      " 20  rents_count                                 931857 non-null  float64\n",
      " 21  bill_total                                  931857 non-null  float64\n",
      " 22  bonus_total                                 931857 non-null  float64\n",
      " 23  last_month_ride                             931857 non-null  float64\n",
      " 24  avg_week_rents                              931857 non-null  float64\n",
      " 25  tariff                                      931857 non-null  object \n",
      " 26  DrivingStyle_delimobilScore                 931857 non-null  object \n",
      " 27  %_total_paid_invoices_sum                   931857 non-null  float64\n",
      " 28  total_invoices_no_payment                   931857 non-null  int32  \n",
      " 29  %_paid_rent_invoices_sum                    931857 non-null  float64\n",
      " 30  rent_invoices_no_payment                    931857 non-null  int32  \n",
      " 31  %_paid_camera_invoices_sum                  931857 non-null  float64\n",
      " 32  camera_invoices_no_payment                  931857 non-null  int32  \n",
      " 33  %_paid_agreement_invoices_sum               931857 non-null  float64\n",
      " 34  agreement_invoices_no_payment               931857 non-null  int32  \n",
      " 35  %_paid_accident_invoices_sum                931857 non-null  float64\n",
      " 36  accident_invoices_no_payment                931857 non-null  int32  \n",
      " 37  %_paid_other_invoices_sum                   931857 non-null  float64\n",
      " 38  other_invoices_no_payment                   931857 non-null  int32  \n",
      " 39  %_paid_agreement_accident_invoices_sum      931857 non-null  float64\n",
      " 40  agreement_accident_invoices_no_payment      931857 non-null  int32  \n",
      " 41  %_paid_agreement_STD_invoices_sum           931857 non-null  float64\n",
      " 42  agreement_STD_invoices_no_payment           931857 non-null  int32  \n",
      " 43  %_paid_agreement_evacuation_invoices_sum    931857 non-null  float64\n",
      " 44  agreement_evacuation_invoices_no_payment    931857 non-null  int32  \n",
      " 45  %_paid_agreement_new_injuries_invoices_sum  931857 non-null  float64\n",
      " 46  agreement_new_injuries_invoices_no_payment  931857 non-null  int32  \n",
      " 47  %_paid_agreement_other_invoices_sum         931857 non-null  float64\n",
      "dtypes: float64(21), int32(10), int64(2), object(15)\n",
      "memory usage: 312.8+ MB\n"
     ]
    }
   ],
   "source": [
    "df_usg_train.info(verbose = True, null_counts = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING REG DATA LOGISTIC REGRESSION ON EVERY TYPE OF INVOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_invoices_no_payment 0.19040282299147634 0.836845981753216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement_invoices_no_payment 0.29691111055888275 0.6917648614158272\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement_accident_invoices_no_payment 0.2621455729231381 0.7647998529556517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement_STD_invoices_no_payment 0.26599736587062944 0.7528276463651161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement_evacuation_invoices_no_payment 0.16783877140230113 0.8874610043987748\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement_new_injuries_invoices_no_payment 0.27258268929698565 0.7723138817177527\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement_other_invoices_no_payment 0.2696503566014761 0.7484853751611168\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident_invoices_no_payment 0.24216595015034417 0.8040271864953341\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s finished\n"
     ]
    }
   ],
   "source": [
    "X = df_reg[['mobile_operator', 'brand', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'sex',\\\n",
    "            'license_category_grouped', 'kbm_grouped', 'psp_region', 'pd_basis_60_v3_4']]\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), ['mobile_operator', 'brand', 'gen_grouped', 'bp_region_group_detailed', 'sex',\\\n",
    "            'license_category_grouped', 'kbm_grouped', 'psp_region']), remainder='passthrough')\n",
    "\n",
    "# PIPELINE (BY DATA SCHOOL)\n",
    "logreg = LogisticRegression(solver = 'lbfgs', class_weight = 'balanced', max_iter = 100, verbose = 1)\n",
    "pipe = make_pipeline(column_trans, logreg)\n",
    "\n",
    "# PIPELINE (BY SCIKIT)\n",
    "model = make_pipeline(column_trans, logreg)\n",
    "\n",
    "for i in ['camera_invoices_no_payment','agreement_invoices_no_payment','agreement_accident_invoices_no_payment',\\\n",
    "          'agreement_STD_invoices_no_payment','agreement_evacuation_invoices_no_payment',\\\n",
    "          'agreement_new_injuries_invoices_no_payment','agreement_other_invoices_no_payment','accident_invoices_no_payment']:\n",
    "    y = df_reg[i]\n",
    "    _ = model.fit(X,y)\n",
    "    y_pred = model.predict(X)\n",
    "    mae = mean_absolute_error(y,y_pred)\n",
    "    roc_auc = roc_auc_score(y,y_pred)\n",
    "    print(i, mae, roc_auc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TESTING USAGE DATA LOGISTICAL REGRESSION ON EVERY TYPE OF INVOICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total_invoices_no_payment 0.3062220170490476 0.30678167606809503 0.7309764698539204 0.730773836633257\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "rent_invoices_no_payment 0.49933705174579884 0.5006766498874358 0.6919890983802548 0.688949966983652\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "camera_invoices_no_payment 0.16104688909687265 0.1611501783320264 0.808926667639014 0.8116478684253392\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   14.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "agreement_invoices_no_payment 0.19738362043524818 0.1959533807199049 0.7422764960024931 0.7509037824632497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   13.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accident_invoices_no_payment 0.3001005489085068 0.29956302329699236 0.7617959970424053 0.7708363454196085\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:940: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  extra_warning_msg=_LOGISTIC_SOLVER_CONVERGENCE_MSG)\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:   17.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "other_invoices_no_payment 0.3743981821094613 0.3731629271747654 0.6957219928638533 0.6979292430646642\n"
     ]
    }
   ],
   "source": [
    "# CONVERTING OBJECT TYPES TO FLOAT\n",
    "for i in ['years_since_last_ride','rents_count', 'bill_total','last_month_ride', 'avg_week_rents']:\n",
    "    df_usg[i] = df_usg[i].replace('NaN',np.nan)\n",
    "df_usg = df_usg.dropna(axis = 'rows', subset = ['years_since_activation','years_since_last_ride','rents_count',\\\n",
    "                                                'bill_total','last_month_ride', 'avg_week_rents'])\n",
    "df_usg.reset_index(drop = True, inplace = True)\n",
    "\n",
    "# RUNNING THE MODEL\n",
    "X = df_usg[['mobile_operator', 'brand', 'gen_grouped', 'age', 'exp', 'bp_region_group_detailed', 'sex',\\\n",
    "            'license_category_grouped', 'kbm_grouped', 'psp_region', 'years_since_activation', 'years_since_last_ride',\\\n",
    "            'rents_count', 'bill_total','last_month_ride', 'avg_week_rents', 'tariff']]\n",
    "\n",
    "column_trans = make_column_transformer(\n",
    "    (OneHotEncoder(), ['mobile_operator', 'brand', 'gen_grouped', 'bp_region_group_detailed', 'sex',\\\n",
    "                       'license_category_grouped', 'kbm_grouped', 'psp_region','tariff']), remainder='passthrough')\n",
    "\n",
    "# PIPELINE (BY DATA SCHOOL)\n",
    "logreg = LogisticRegression(solver = 'lbfgs', class_weight = 'balanced', max_iter = 100, verbose = 1)\n",
    "pipe = make_pipeline(column_trans, logreg)\n",
    "\n",
    "# PIPELINE (BY SCIKIT)\n",
    "model = make_pipeline(column_trans, logreg)\n",
    "\n",
    "for i in ['total_invoices_no_payment', 'rent_invoices_no_payment','camera_invoices_no_payment','agreement_invoices_no_payment',\\\n",
    "          'accident_invoices_no_payment', 'other_invoices_no_payment']:\n",
    "    y = df_usg[i]\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y)\n",
    "    model.fit(X_train,y_train)\n",
    "    y_train_pred = model.predict(X_train)\n",
    "    y_test_pred = model.predict(X_test)\n",
    "    mae_train = mean_absolute_error(y_train,y_train_pred)\n",
    "    roc_auc_train = roc_auc_score(y_train,y_train_pred)\n",
    "    mae_test = mean_absolute_error(y_test,y_test_pred)\n",
    "    roc_auc_test = roc_auc_score(y_test,y_test_pred)\n",
    "#     save_df = pd.concat([X, pd.Series(y), pd.Series(y_pred)], axis=1)\n",
    "#     save_df.to_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/v2/'+i+'.csv', index = False, encoding='utf-8-sig')\n",
    "    print(i, mae_train, mae_test, roc_auc_train, roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 1265056 entries, 0 to 1265055\n",
      "Data columns (total 121 columns):\n",
      " #   Column                                      Non-Null Count    Dtype  \n",
      "---  ------                                      --------------    -----  \n",
      " 0   user_id                                     1265056 non-null  int64  \n",
      " 1   mobile_code                                 1265056 non-null  int64  \n",
      " 2   age                                         1265056 non-null  float64\n",
      " 3   exp                                         1265056 non-null  float64\n",
      " 4   birth_place                                 1265056 non-null  object \n",
      " 5   city                                        1265056 non-null  object \n",
      " 6   country                                     1265056 non-null  object \n",
      " 7   sex                                         1265056 non-null  object \n",
      " 8   region_name_en                              1265056 non-null  object \n",
      " 9   license_category                            1265056 non-null  object \n",
      " 10  PassportRegistration                        1265056 non-null  object \n",
      " 11  PassportDepartmentCode                      1265056 non-null  object \n",
      " 12  years_since_registration                    1265056 non-null  float64\n",
      " 13  years_since_activation                      1265056 non-null  float64\n",
      " 14  years_since_last_ride                       1265056 non-null  float64\n",
      " 15  rents_count                                 1265056 non-null  float64\n",
      " 16  bill_total                                  1265056 non-null  float64\n",
      " 17  bonus_total                                 1265056 non-null  object \n",
      " 18  last_month_ride                             1265056 non-null  float64\n",
      " 19  avg_week_rents                              1265056 non-null  float64\n",
      " 20  rent_region                                 1265056 non-null  object \n",
      " 21  country_ext                                 1265056 non-null  object \n",
      " 22  tariff                                      1265056 non-null  object \n",
      " 23  total_invoices_sum                          1265056 non-null  float64\n",
      " 24  rent_invoices_sum                           1265056 non-null  float64\n",
      " 25  camera_invoices_sum                         1265056 non-null  float64\n",
      " 26  agreement_invoices_sum                      1265056 non-null  float64\n",
      " 27  accident_invoices_sum                       1265056 non-null  float64\n",
      " 28  other_invoices_sum                          1265056 non-null  float64\n",
      " 29  total_paid_invoices_3_days_sum              1265056 non-null  float64\n",
      " 30  total_paid_invoices_7_days_sum              1265056 non-null  float64\n",
      " 31  total_paid_invoices_30_days_sum             1265056 non-null  float64\n",
      " 32  total_paid_invoices_60_days_sum             1265056 non-null  float64\n",
      " 33  total_paid_invoices_90_days_sum             1265056 non-null  float64\n",
      " 34  total_paid_invoices_180_days_sum            1265056 non-null  float64\n",
      " 35  total_paid_invoices_sum                     1265056 non-null  float64\n",
      " 36  paid_rent_invoices_3_days_sum               1265056 non-null  float64\n",
      " 37  paid_rent_invoices_7_days_sum               1265056 non-null  float64\n",
      " 38  paid_rent_invoices_30_days_sum              1265056 non-null  float64\n",
      " 39  paid_rent_invoices_60_days_sum              1265056 non-null  float64\n",
      " 40  paid_rent_invoices_90_days_sum              1265056 non-null  float64\n",
      " 41  paid_rent_invoices_180_days_sum             1265056 non-null  float64\n",
      " 42  paid_rent_invoices_sum                      1265056 non-null  float64\n",
      " 43  paid_camera_invoices_3_days_sum             1265056 non-null  float64\n",
      " 44  paid_camera_invoices_7_days_sum             1265056 non-null  float64\n",
      " 45  paid_camera_invoices_30_days_sum            1265056 non-null  float64\n",
      " 46  paid_camera_invoices_60_days_sum            1265056 non-null  float64\n",
      " 47  paid_camera_invoices_90_days_sum            1265056 non-null  float64\n",
      " 48  paid_camera_invoices_180_days_sum           1265056 non-null  float64\n",
      " 49  paid_camera_invoices_sum                    1265056 non-null  float64\n",
      " 50  paid_agreement_invoices_3_days_sum          1265056 non-null  float64\n",
      " 51  paid_agreement_invoices_7_days_sum          1265056 non-null  float64\n",
      " 52  paid_agreement_invoices_30_days_sum         1265056 non-null  float64\n",
      " 53  paid_agreement_invoices_60_days_sum         1265056 non-null  float64\n",
      " 54  paid_agreement_invoices_90_days_sum         1265056 non-null  float64\n",
      " 55  paid_agreement_invoices_180_days_sum        1265056 non-null  float64\n",
      " 56  paid_agreement_invoices_sum                 1265056 non-null  float64\n",
      " 57  paid_accident_invoices_3_days_sum           1265056 non-null  float64\n",
      " 58  paid_accident_invoices_7_days_sum           1265056 non-null  float64\n",
      " 59  paid_accident_invoices_30_days_sum          1265056 non-null  float64\n",
      " 60  paid_accident_invoices_60_days_sum          1265056 non-null  float64\n",
      " 61  paid_accident_invoices_90_days_sum          1265056 non-null  float64\n",
      " 62  paid_accident_invoices_180_days_sum         1265056 non-null  float64\n",
      " 63  paid_accident_invoices_sum                  1265056 non-null  float64\n",
      " 64  paid_other_invoices_3_days_sum              1265056 non-null  float64\n",
      " 65  paid_other_invoices_7_days_sum              1265056 non-null  float64\n",
      " 66  paid_other_invoices_30_days_sum             1265056 non-null  float64\n",
      " 67  paid_other_invoices_60_days_sum             1265056 non-null  float64\n",
      " 68  paid_other_invoices_90_days_sum             1265056 non-null  float64\n",
      " 69  paid_other_invoices_180_days_sum            1265056 non-null  float64\n",
      " 70  paid_other_invoices_sum                     1265056 non-null  float64\n",
      " 71  agreement_accident_invoices_sum             1265056 non-null  float64\n",
      " 72  agreement_STD_invoices_sum                  1265056 non-null  float64\n",
      " 73  agreement_evacuation_invoices_sum           1265056 non-null  float64\n",
      " 74  agreement_new_injuries_invoices_sum         1265056 non-null  float64\n",
      " 75  agreement_other_invoices_sum                1265056 non-null  float64\n",
      " 76  paid_agreement_accident_invoices_sum        1265056 non-null  float64\n",
      " 77  paid_agreement_STD_invoices_sum             1265056 non-null  float64\n",
      " 78  paid_agreement_evacuation_invoices_sum      1265056 non-null  float64\n",
      " 79  paid_agreement_new_injuries_invoices_sum    1265056 non-null  float64\n",
      " 80  paid_agreement_other_invoices_sum           1265056 non-null  float64\n",
      " 81  PassportDepartmentRegionCode                1265056 non-null  object \n",
      " 82  %_total_paid_invoices_sum                   1265056 non-null  float64\n",
      " 83  total_invoices_no_payment                   1265056 non-null  int32  \n",
      " 84  %_paid_rent_invoices_sum                    1265056 non-null  float64\n",
      " 85  rent_invoices_no_payment                    1265056 non-null  int32  \n",
      " 86  %_paid_camera_invoices_sum                  1265056 non-null  float64\n",
      " 87  camera_invoices_no_payment                  1265056 non-null  int32  \n",
      " 88  %_paid_agreement_invoices_sum               1265056 non-null  float64\n",
      " 89  agreement_invoices_no_payment               1265056 non-null  int32  \n",
      " 90  %_paid_accident_invoices_sum                1265056 non-null  float64\n",
      " 91  accident_invoices_no_payment                1265056 non-null  int32  \n",
      " 92  %_paid_other_invoices_sum                   1265056 non-null  float64\n",
      " 93  other_invoices_no_payment                   1265056 non-null  int32  \n",
      " 94  %_paid_agreement_accident_invoices_sum      1265056 non-null  float64\n",
      " 95  agreement_accident_invoices_no_payment      1265056 non-null  int32  \n",
      " 96  %_paid_agreement_STD_invoices_sum           1265056 non-null  float64\n",
      " 97  agreement_STD_invoices_no_payment           1265056 non-null  int32  \n",
      " 98  %_paid_agreement_evacuation_invoices_sum    1265056 non-null  float64\n",
      " 99  agreement_evacuation_invoices_no_payment    1265056 non-null  int32  \n",
      " 100 %_paid_agreement_new_injuries_invoices_sum  1265056 non-null  float64\n",
      " 101 agreement_new_injuries_invoices_no_payment  1265056 non-null  int32  \n",
      " 102 %_paid_agreement_other_invoices_sum         1265056 non-null  float64\n",
      " 103 agreement_other_invoices_no_payment         1265056 non-null  int32  \n",
      " 104 device_type                                 1256996 non-null  object \n",
      " 105 brand                                       1254137 non-null  object \n",
      " 106 device_gen                                  1254137 non-null  object \n",
      " 107 branded_gen_grouped                         1254137 non-null  object \n",
      " 108 gen_grouped                                 1254137 non-null  object \n",
      " 109 kbm                                         1082998 non-null  float64\n",
      " 110 kbm_grouped                                 1082998 non-null  object \n",
      " 111 PassportBirthPlace                          860047 non-null   object \n",
      " 112 region                                      860047 non-null   object \n",
      " 113 bp_region                                   746078 non-null   object \n",
      " 114 bp_region_group_detailed                    737711 non-null   object \n",
      " 115 mobile_operator                             1264752 non-null  object \n",
      " 116 license_category_grouped                    248803 non-null   object \n",
      " 117 psp_region_code                             499377 non-null   object \n",
      " 118 psp_region                                  499377 non-null   object \n",
      " 119 psp_fed_district                            499377 non-null   object \n",
      " 120 DrivingStyle_delimobilScore                 462203 non-null   float64\n",
      "dtypes: float64(80), int32(11), int64(2), object(28)\n",
      "memory usage: 1.1+ GB\n"
     ]
    }
   ],
   "source": [
    "df.info(verbose = True, null_counts = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
