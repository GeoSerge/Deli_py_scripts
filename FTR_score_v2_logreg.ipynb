{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.compose import make_column_transformer\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import seaborn as sn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\pandas\\core\\series.py:679: RuntimeWarning: divide by zero encountered in log\n",
      "  result = getattr(ufunc, method)(*inputs, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "# UPLOADING THE MAIN DATASET\n",
    "df = pd.read_csv('C:/Users/sgulbin/Work/Analysis/FTR_score_v2/dataset.csv', low_memory = False)\n",
    "\n",
    "df['age'] = np.where(((df.age < 18)|(df.age>65)),np.nan,df.age)\n",
    "df['exp'] = np.where(((df.exp < 0)|(df.exp>47)),np.nan,df.exp)\n",
    "df = df.dropna(axis = 'rows', subset = ['age','exp'])\n",
    "\n",
    "df['ln_age'] = np.log(df.age)\n",
    "df['0'] = 0\n",
    "df['ln_exp'] = np.log(df.exp)\n",
    "df['ln_exp'] = df[['ln_exp','0']].max(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# PREPARING BIRTH PLACE REGION DATAFRAME\n",
    "bp = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/birthplaces_lib.csv')\n",
    "bp = bp[['PassportBirthPlace','country','region']]\n",
    "bp = bp.replace('None', np.nan)\n",
    "bp = bp.dropna(axis='rows')\n",
    "bp = bp.drop_duplicates(subset = ['PassportBirthPlace'])\n",
    "\n",
    "# BIRTH PLACES LIB\n",
    "bp_clsfied = pd.read_csv('C:/Users/sgulbin/Work/Analysis/Платежеспособность/data_lib/birthplaces_classified_lib.csv')\n",
    "\n",
    "# COUNTRIES\n",
    "countries = bp_clsfied.drop_duplicates(subset = 'bp_country')\n",
    "countries = pd.concat([countries.iloc[1:2],countries.iloc[3:]], axis='rows')\n",
    "countries = countries[['bp_country', 'bp_region_group_detailed']]\n",
    "\n",
    "# MERGING\n",
    "bp = pd.merge(bp, bp_clsfied, left_on = 'region', right_on = 'bp_region_group_detailed', how = 'left')\n",
    "bp = pd.merge(bp, countries, left_on = 'country', right_on = 'bp_country', how = 'left')\n",
    "\n",
    "bp['bp_region_group_detailed'] = np.where(pd.isnull(bp.bp_region_group_detailed_x) == True,bp.bp_region_group_detailed_y,\\\n",
    "                                            bp.bp_region_group_detailed_x)\n",
    "bp = bp[['PassportBirthPlace', 'bp_region_group_detailed']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MERGING\n",
    "df = pd.merge(df, bp, left_on = 'birth_place', right_on = 'PassportBirthPlace', how = 'left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accidents_count ; train: 0.6641994089809309 ; test: 0.6585497332080867\n",
      "count_0_20 ; train: 0.6691406036539272 ; test: 0.6500496559478128\n",
      "count_20_40 ; train: 0.6949435191023937 ; test: 0.6288542558316682\n",
      "count_40_100 ; train: 0.7024246845721843 ; test: 0.6451334657756698\n",
      "count_100 ; train: 0.7285081283156214 ; test: 0.6679064741688121\n"
     ]
    }
   ],
   "source": [
    "# DEFINING X AND Y\n",
    "X = df[['sex', 'ln_age', 'ln_exp', 'bp_region_group_detailed', 'kbm_grouped','license_category_grouped']]\n",
    "X = X.fillna('NaN')\n",
    "\n",
    "for target in ['accidents_count', 'count_0_20', 'count_20_40', 'count_40_100', 'count_100']:\n",
    "    \n",
    "    # CONVERTING % VALUES INTO BOOLEAN\n",
    "    df['default_user'] = np.where(df[target] > 0,1,0)                  \n",
    "    y = df['default_user']\n",
    "        \n",
    "    # SPLITTING DATASET INTO TRAIN AND TEST SAMPLES\n",
    "    x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n",
    "\n",
    "    # ONE-HOT ENCODING VARIABLES\n",
    "    column_trans = make_column_transformer((StandardScaler(), list(x_train.loc[:, x_train.dtypes == float].columns)),\n",
    "                                           (OneHotEncoder(), list(x_train.loc[:, x_train.dtypes == object])),\\\n",
    "                                            remainder = 'passthrough')\n",
    "    # PIPELINE SET UP\n",
    "    logreg = LogisticRegression(solver = 'lbfgs', class_weight = 'balanced', max_iter = 1000)\n",
    "    model = make_pipeline(column_trans, logreg)\n",
    "    _ = model.fit(x_train,y_train)\n",
    "    y_pred_train = model.predict(x_train)\n",
    "    y_pred_test = model.predict(x_test)\n",
    "    roc_auc_train = roc_auc_score(y_train,y_pred_train)\n",
    "    roc_auc_test = roc_auc_score(y_test,y_pred_test)\n",
    "    print(target,';','train:',roc_auc_train,';','test:',roc_auc_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "C:\\ProgramData\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 753714 entries, 0 to 753774\n",
      "Data columns (total 23 columns):\n",
      " #   Column             Non-Null Count   Dtype\n",
      "---  ------             --------------   -----\n",
      " 0   age_grouped        753714 non-null  int32\n",
      " 1   exp_grouped        753714 non-null  int32\n",
      " 2   F                  753714 non-null  uint8\n",
      " 3   M                  753714 non-null  uint8\n",
      " 4   only_B             753714 non-null  uint8\n",
      " 5   other_than_B       753714 non-null  uint8\n",
      " 6   no_region          753714 non-null  uint8\n",
      " 7   Дальневосточный    753714 non-null  uint8\n",
      " 8   Приволжский        753714 non-null  uint8\n",
      " 9   Северо-Западный    753714 non-null  uint8\n",
      " 10  Северо-Кавказский  753714 non-null  uint8\n",
      " 11  Сибирский          753714 non-null  uint8\n",
      " 12  Уральский          753714 non-null  uint8\n",
      " 13  Центральный        753714 non-null  uint8\n",
      " 14  Южный              753714 non-null  uint8\n",
      " 15  no_kbm             753714 non-null  uint8\n",
      " 16  0.5+               753714 non-null  uint8\n",
      " 17  0.7+               753714 non-null  uint8\n",
      " 18  0.8+               753714 non-null  uint8\n",
      " 19  0.9+               753714 non-null  uint8\n",
      " 20  1                  753714 non-null  uint8\n",
      " 21  1.4+               753714 non-null  uint8\n",
      " 22  2.3+               753714 non-null  uint8\n",
      "dtypes: int32(2), uint8(21)\n",
      "memory usage: 46.6 MB\n"
     ]
    }
   ],
   "source": [
    "columns = ['sex', 'age_grouped', 'exp_grouped', 'other_than_B', 'kbm_grouped', 'Region_group', 'accidents_fact']\n",
    "ds = df[columns]\n",
    "ds['Region_group'] = ds['Region_group'].fillna(0)\n",
    "ds['kbm_grouped'] = ds['kbm_grouped'].fillna(0)\n",
    "ds['age_grouped'] = ds['age_grouped'].replace('50+',50)\n",
    "ds = ds.dropna(subset=['age_grouped'], how = 'any')\n",
    "ds['age_grouped'] = ds['age_grouped'].astype(str).astype(int)\n",
    "ds['exp_grouped'] = ds['exp_grouped'].replace('32+',32)\n",
    "ds['exp_grouped'] = ds['exp_grouped'].astype(str).astype(int)\n",
    "oh_sex = pd.get_dummies(ds['sex'])\n",
    "oh_lcns = pd.get_dummies(ds['other_than_B'])\n",
    "oh_lcns.columns = ['only_B', 'other_than_B']\n",
    "oh_rgn = pd.get_dummies(ds['Region_group'])\n",
    "oh_rgn.columns = oh_rgn.columns = ['no_region']+list(oh_rgn.columns[1:])\n",
    "oh_kbm = pd.get_dummies(ds['kbm_grouped'])\n",
    "oh_kbm.columns = oh_kbm.columns = ['no_kbm']+list(oh_kbm.columns[1:])\n",
    "ds = ds.drop(['sex', 'other_than_B', 'Region_group', 'kbm_grouped'], axis = 1)\n",
    "ds = ds.join(oh_sex)\n",
    "ds = ds.join(oh_lcns)\n",
    "ds = ds.join(oh_rgn)\n",
    "ds = ds.join(oh_kbm)\n",
    "y = ds['accidents_fact']\n",
    "ds = ds.drop(['accidents_fact'], axis = 1)\n",
    "X = ds\n",
    "X.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6763108726910192\n"
     ]
    }
   ],
   "source": [
    "from xgboost import XGBRegressor\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import tree\n",
    "features = [['age_grouped','exp_grouped'],['F','M'],['only_B', 'other_than_B'],\\\n",
    "            ['no_region','Дальневосточный','Приволжский','Северо-Западный','Северо-Кавказский', 'Сибирский', 'Уральский', 'Центральный', 'Южный'],\\\n",
    "            ['0.5+','0.7+','0.8+','0.9+','1','1.4+','2.3+']]\n",
    "X = X[['age_grouped','exp_grouped','0.5+','0.7+','0.8+','0.9+','1','1.4+','2.3+','F','M']]\n",
    "train_X, val_X, train_y, val_y = train_test_split(X, y, random_state=1)\n",
    "model = XGBRegressor()\n",
    "\n",
    "model.fit(train_X, train_y)\n",
    "val_predictions = model.predict(val_X)\n",
    "val_roc_auc = roc_auc_score(val_y, val_predictions) \n",
    "print(val_roc_auc)\n",
    "# tree.plot_tree(model)\n",
    "# tree.plot_tree(model,\n",
    "#                feature_names = X.columns, \n",
    "#                filled = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 0, Score: 0.04762\n",
      "Feature: 1, Score: 0.06298\n",
      "Feature: 2, Score: 0.05945\n",
      "Feature: 3, Score: 0.00000\n",
      "Feature: 4, Score: 0.06045\n",
      "Feature: 5, Score: 0.00000\n",
      "Feature: 6, Score: 0.04415\n",
      "Feature: 7, Score: 0.04885\n",
      "Feature: 8, Score: 0.05262\n",
      "Feature: 9, Score: 0.03585\n",
      "Feature: 10, Score: 0.04398\n",
      "Feature: 11, Score: 0.04260\n",
      "Feature: 12, Score: 0.04066\n",
      "Feature: 13, Score: 0.03783\n",
      "Feature: 14, Score: 0.04083\n",
      "Feature: 15, Score: 0.06572\n",
      "Feature: 16, Score: 0.03706\n",
      "Feature: 17, Score: 0.02916\n",
      "Feature: 18, Score: 0.03053\n",
      "Feature: 19, Score: 0.06340\n",
      "Feature: 20, Score: 0.07476\n",
      "Feature: 21, Score: 0.02725\n",
      "Feature: 22, Score: 0.05422\n"
     ]
    }
   ],
   "source": [
    "# linear regression feature importance\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.datasets import make_regression\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from matplotlib import pyplot\n",
    "# define dataset\n",
    "# X, y = make_regression(n_samples=1000, n_features=10, n_informative=5, random_state=1)\n",
    "# define the model\n",
    "# model = DecisionTreeRegressor()\n",
    "model = XGBRegressor()\n",
    "# fit the model\n",
    "model.fit(X, y)\n",
    "# get importance\n",
    "importance = model.feature_importances_\n",
    "# summarize feature importance\n",
    "for i,v in enumerate(importance):\n",
    "\tprint('Feature: %0d, Score: %.5f' % (i,v))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "age_grouped\n",
      "exp_grouped\n",
      "F\n",
      "M\n",
      "only_B\n",
      "other_than_B\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-83-b39cd547a313>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m             \u001b[1;33m[\u001b[0m\u001b[1;34m'no_region'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Дальневосточный'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Приволжский'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Северо-Западный'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Северо-Кавказский'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Сибирский'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Уральский'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Центральный'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Южный'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m             ['0.5+','0.7+','0.8+','0.9+','1','1.4+','2.3+']]\n\u001b[1;32m----> 4\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0me\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mfeatures\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: too many values to unpack (expected 2)"
     ]
    }
   ],
   "source": [
    "features = [['age_grouped','exp_grouped'],['F','M'],['only_B', 'other_than_B'],\\\n",
    "            ['no_region','Дальневосточный','Приволжский','Северо-Западный','Северо-Кавказский', 'Сибирский', 'Уральский', 'Центральный', 'Южный'],\\\n",
    "            ['0.5+','0.7+','0.8+','0.9+','1','1.4+','2.3+']]\n",
    "for i,e in features:\n",
    "    print(i)\n",
    "    print(e)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
